{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sprint 2\n",
    "https://www.kaggle.com/code/ramantalwar00/classsification-restaurant-price-final/notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification of resaurant\n",
    "When you get restaurant recommendations as a user you might want a functionality to filter out restaurants on price range. As a restaurant owner you might want to know what other restaurant features influence your price tag. That's why we want to create a classification model that classifies restaurants into cheap, medium of expensive categories.\n",
    "\n",
    "To do this we will try out different clasifiers on default settings and then do a gridsearch on the most promising ones to get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfastai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimports\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m KNeighborsClassifier\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\fastai\\imports.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mio\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39moperator\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39msys\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mre\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mmimetypes\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mcsv\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mitertools\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mjson\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mshutil\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mglob\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mpickle\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mtarfile\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mcollections\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhashlib\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mitertools\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mtypes\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39minspect\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mfunctools\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mrandom\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mtime\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mmath\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mbz2\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mtyping\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mnumbers\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mstring\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mthreading\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39murllib\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mtempfile\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mconcurrent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfutures\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mmatplotlib\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mwarnings\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mzipfile\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconcurrent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfutures\u001b[39;00m \u001b[39mimport\u001b[39;00m as_completed\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m partial,reduce\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\matplotlib\\__init__.py:109\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m parse \u001b[39mas\u001b[39;00m parse_version\n\u001b[0;32m    107\u001b[0m \u001b[39m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, _version, cbook, docstring, rcsetup\n\u001b[0;32m    110\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m MatplotlibDeprecationWarning, sanitize_sequence\n\u001b[0;32m    111\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m mplDeprecation  \u001b[39m# deprecated\u001b[39;00m\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\matplotlib\\rcsetup.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m ls_mapper\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolors\u001b[39;00m \u001b[39mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfontconfig_pattern\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_enums\u001b[39;00m \u001b[39mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     31\u001b[0m \u001b[39m# Don't let the original cycler collide with our validating cycler\u001b[39;00m\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\matplotlib\\fontconfig_pattern.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyparsing\u001b[39;00m \u001b[39mimport\u001b[39;00m (Literal, ZeroOrMore, Optional, Regex, StringEnd,\n\u001b[0;32m     16\u001b[0m                        ParseException, Suppress)\n\u001b[0;32m     18\u001b[0m family_punc \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39m-:,\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     19\u001b[0m family_unescape \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m([\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m])\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m family_punc)\u001b[39m.\u001b[39msub\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\pyparsing\\__init__.py:140\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    139\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mactions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m--> 140\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m __diag__, __compat__\n\u001b[0;32m    141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresults\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\pyparsing\\core.py:5663\u001b[0m\n\u001b[0;32m   5660\u001b[0m string_start \u001b[39m=\u001b[39m StringStart()\u001b[39m.\u001b[39mset_name(\u001b[39m\"\u001b[39m\u001b[39mstring_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5661\u001b[0m string_end \u001b[39m=\u001b[39m StringEnd()\u001b[39m.\u001b[39mset_name(\u001b[39m\"\u001b[39m\u001b[39mstring_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 5663\u001b[0m _escapedPunc \u001b[39m=\u001b[39m Word(_bslash, \u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m[]-*.$+^?()~ \u001b[39;49m\u001b[39m\"\u001b[39;49m, exact\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mset_parse_action(\n\u001b[0;32m   5664\u001b[0m     \u001b[39mlambda\u001b[39;49;00m s, l, t: t[\u001b[39m0\u001b[39;49m][\u001b[39m1\u001b[39;49m]\n\u001b[0;32m   5665\u001b[0m )\n\u001b[0;32m   5666\u001b[0m _escapedHexChar \u001b[39m=\u001b[39m Regex(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m0?[xX][0-9a-fA-F]+\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mset_parse_action(\n\u001b[0;32m   5667\u001b[0m     \u001b[39mlambda\u001b[39;00m s, l, t: \u001b[39mchr\u001b[39m(\u001b[39mint\u001b[39m(t[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mlstrip(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m0x\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m16\u001b[39m))\n\u001b[0;32m   5668\u001b[0m )\n\u001b[0;32m   5669\u001b[0m _escapedOctChar \u001b[39m=\u001b[39m Regex(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m0[0-7]+\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mset_parse_action(\n\u001b[0;32m   5670\u001b[0m     \u001b[39mlambda\u001b[39;00m s, l, t: \u001b[39mchr\u001b[39m(\u001b[39mint\u001b[39m(t[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m:], \u001b[39m8\u001b[39m))\n\u001b[0;32m   5671\u001b[0m )\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\pyparsing\\core.py:675\u001b[0m, in \u001b[0;36mParserElement.set_parse_action\u001b[1;34m(self, *fns, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(callable(fn) \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m fns):\n\u001b[0;32m    674\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mparse actions must be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 675\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparseAction \u001b[39m=\u001b[39m [_trim_arity(fn) \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m fns]\n\u001b[0;32m    676\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallDuringTry \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[0;32m    677\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcall_during_try\u001b[39m\u001b[39m\"\u001b[39m, kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcallDuringTry\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    678\u001b[0m     )\n\u001b[0;32m    679\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\pyparsing\\core.py:675\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(callable(fn) \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m fns):\n\u001b[0;32m    674\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mparse actions must be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 675\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparseAction \u001b[39m=\u001b[39m [_trim_arity(fn) \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m fns]\n\u001b[0;32m    676\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallDuringTry \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[0;32m    677\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcall_during_try\u001b[39m\u001b[39m\"\u001b[39m, kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcallDuringTry\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    678\u001b[0m     )\n\u001b[0;32m    679\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\pyparsing\\core.py:284\u001b[0m, in \u001b[0;36m_trim_arity\u001b[1;34m(func, max_limit)\u001b[0m\n\u001b[0;32m    281\u001b[0m LINE_DIFF \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m\n\u001b[0;32m    282\u001b[0m \u001b[39m# IF ANY CODE CHANGES, EVEN JUST COMMENTS OR BLANK LINES, BETWEEN THE NEXT LINE AND\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[39m# THE CALL TO FUNC INSIDE WRAPPER, LINE_DIFF MUST BE MODIFIED!!!!\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m _trim_arity_call_line \u001b[39m=\u001b[39m (_trim_arity_call_line \u001b[39mor\u001b[39;00m traceback\u001b[39m.\u001b[39;49mextract_stack(limit\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m    285\u001b[0m pa_call_line_synth \u001b[39m=\u001b[39m (_trim_arity_call_line[\u001b[39m0\u001b[39m], _trim_arity_call_line[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m LINE_DIFF)\n\u001b[0;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs):\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 211\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[0;32m    212\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\traceback.py:366\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n\u001b[0;32m    365\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m result:\n\u001b[1;32m--> 366\u001b[0m         f\u001b[39m.\u001b[39;49mline\n\u001b[0;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\traceback.py:288\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mline\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39m=\u001b[39m linecache\u001b[39m.\u001b[39;49mgetline(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlineno)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetline\u001b[39m(filename, lineno, module_globals\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m     \u001b[39m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     lines \u001b[39m=\u001b[39m getlines(filename, module_globals)\n\u001b[0;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m lineno \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lines):\n\u001b[0;32m     32\u001b[0m         \u001b[39mreturn\u001b[39;00m lines[lineno \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m cache[filename][\u001b[39m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[39mreturn\u001b[39;00m updatecache(filename, module_globals)\n\u001b[0;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mMemoryError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\linecache.py:137\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[39mwith\u001b[39;00m tokenize\u001b[39m.\u001b[39mopen(fullname) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m--> 137\u001b[0m         lines \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mreadlines()\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_buffer_decode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, errors, final):\n\u001b[0;32m    315\u001b[0m     \u001b[39m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m    322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_decode(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors, final)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from fastai.imports import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "original_df = pd.read_csv(\"tripadvisor_dataset/restaurant_listings.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in short, we will do the same preprocessing as we did in sprint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see notebook sprint 1 for details on how we got this\n",
    "coords=pd.read_csv(\"tripadvisor_dataset\\coordinaten2.csv\").replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df[\"rank\"]=original_df[\"rank\"].str.replace(\"#\",\"\").astype(float)\n",
    "original_df[\"general rating\"]=original_df[\"general rating\"].map(lambda x: x.split(\" \")[0]).astype(float)\n",
    "original_df[\"number of reviews\"]=original_df[\"number of reviews\"].map(lambda x: x.split(\" \")[0].replace(\",\",\"\")).astype(float)\n",
    "original_df['city'] = original_df[\"address\"].str.split(', ').str[-1].str.split(\" \").str[0]\n",
    "first_tag=original_df.tags.str.split(\"|\",expand=True)[0].dropna()\n",
    "ranges=first_tag[first_tag.str.find(\"$\")!=-1]\n",
    "original_df[\"price_tag\"]=ranges\n",
    "original_df=original_df.merge(coords,on=\"id\")\n",
    "original_df.drop(columns=[\"food rating\", \"service rating\",\"price range\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE* we can do this preprocessing on the original df because we are not aggregating data, each row is preprocessed individually (we are not using mean/mode/median/...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will split the data and use a seed ;) but because we want to actually have price tags (our labels) we will remove them from our data first before making the train test split. In the end we can use our model to actually fill in the missing price tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_price_tag=original_df[~original_df.price_tag.isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_price_tag.price_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will also remove features that won't help with the classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_price_tag.drop(columns=[\"restaurant name\",\"address\",\"phone number\",\"website url\",\"menu url\",\"timetable\",\"email address\",\"id\",\"tags\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### descriptions\n",
    "\n",
    "We can use the descriptions, we have 2 types. We will first see which ones are the most usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"description is missing: {df_with_price_tag.description.isna().sum()}\")\n",
    "print(f\"dutch description is missing {df_with_price_tag['dutch description'].isna().sum()}\")\n",
    "print(f\"size trainingsset is {len(df_with_price_tag)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have too many missing values for description, 77% of the descriptions is missing so that's why we decided not to include this as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_price_tag.drop(columns=[\"description\",\"dutch description\"],inplace=True)\n",
    "df_with_price_tag.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_with_price_tag,test_size=0.2,train_size=0.8,shuffle=True,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.price_tag.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a big class imabalance in our training data, we have to take this into account. \n",
    "We have multiple options to handle this class imbalance, the first option is to continue with the imbalanced dataset.When choosing our models we will look for algorithms that have the class weight property so we can assign the corresponding weight to each class.\n",
    "\n",
    "The second option is to artificially oversample our minority classes or downsample our majority classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start with the feature engineering part I would start by making a baseline classifier, the random forest. I chose to do this because it is very difficult to do something wrong here, it is insensitive to outliers and does not require feature scaling. The results are also interpretable, we can see which features are used to split our data (the most important features) and we can focus on those in our other classifier models.\n",
    "\n",
    "\n",
    "inspiration from [this](https://www.kaggle.com/code/jhoward/how-random-forests-really-work) notebook used in the course [Practical Deep Learning for Coders 2022](https://www.youtube.com/watch?v=8SF_h3xF3cE&list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU&ab_channel=JeremyHoward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "peronally I also wanted to experiment a bit with pipelines so I got some inspiration from [this blog](https://towardsdatascience.com/getting-the-most-out-of-scikit-learn-pipelines-c2afc4410f1a#:~:text=They%20can%20be%20nested%20and,(model)%20at%20the%20end.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train=df_train.copy()\n",
    "rf_test=df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric=[\"rank\",\"general rating\",\"number of reviews\",\"value rating\",\"atmosphere rating\",\"latitude\",\"longitude\"]\n",
    "mutlihot_col = ['cuisines','special diets',\"meals\",\"restaurant features\"]\n",
    "cat_cols = ['travelers choice', 'michelin', 'city']#one hot encoding\n",
    "label=\"price_tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in mutlihot_col:\n",
    "    rf_train[col]=rf_train[col].fillna(\"X\").str.replace(\" \",\"\").str.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ColumnTransformers are built similarly to Pipelines, except you include a third value in each tuple representing the columns to be transformed in that step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from help_script import MultiHotEncoder\n",
    "\n",
    "cols_trans = ColumnTransformer([\n",
    "    ('mhe',MultiHotEncoder(),mutlihot_col),\n",
    "    ('ohe', OneHotEncoder(drop='first'), cat_cols), \n",
    "    ('imputing',SimpleImputer(),numeric),\n",
    "    ('scaling',StandardScaler(),numeric)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('trans', cols_trans),\n",
    "    ('clf', LogisticRegression(max_iter=500, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.fit(rf_train,rf_train[\"price_tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(100, min_samples_leaf=5)\n",
    "# rf.fit(trn_xs, trn_y);\n",
    "# mean_absolute_error(val_y, rf.predict(val_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's start with the feature engineering part, as we've learned our model can only interpret numbers so as input we must turn all our attributes into numerical values\n",
    "\n",
    "for the attributes that are already numerical we can look for feature scaling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_cols=df_train.select_dtypes(numerics).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,15))\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    plt.subplot(4,2,i+1)\n",
    "    sns.histplot(df_train[col])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rank and number of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see the rank and number of reviews have along tail distribution so I would take the log of the data first, and then apply standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(df_train[\"rank\"])\n",
    "plt.subplot(2,2,2)\n",
    "sns.histplot(np.log(df_train[\"rank\"]))\n",
    "plt.subplot(2,2,3)\n",
    "sns.histplot(df_train[\"number of reviews\"])\n",
    "plt.subplot(2,2,4)\n",
    "sns.histplot(np.log(df_train[\"number of reviews\"]))\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It already looks so much better! we will keep this but because sometimes the number of reviews is zero we will add a +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##WE WILL DO THIS AFTER IMPUTATION\n",
    "# df_train[\"lg_rank\"]=np.log(df_train[\"rank\"])\n",
    "# df_train[\"lg_reviews\"]=np.log(df_train[\"number of reviews\"]+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general rating, atmosphere rating and value rating\n",
    "\n",
    "look at these three again without the -1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "sns.histplot(df_train[\"general rating\"].replace(-1,np.nan))\n",
    "plt.subplot(2,2,2)\n",
    "sns.histplot(df_train[\"atmosphere rating\"].replace(-1,np.nan))\n",
    "plt.subplot(2,2,3)\n",
    "sns.histplot(df_train[\"value rating\"].replace(-1,np.nan))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this already looks acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lat & lon\n",
    "for the coordinates we think it's best just to apply standardization to them\n",
    "\n",
    "and for the missing data we wrote a script that derives the center latitude and longitude from the city and we will fill it in with those coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_centers=pd.read_csv(\"sprint1\\city_centers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.merge(city_centers,on=\"city\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.latitude.isna(),\"latitude\"]=df_train[df_train.latitude.isna()].latitude_center\n",
    "df_train.loc[df_train.longitude.isna(),\"longitude\"]=df_train[df_train.longitude.isna()].longitude_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.latitude.isna().sum()\n",
    "# df_train.loc[df_train.latitude.isna(),\"latitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=[\"Unnamed: 0\",\"latitude_center\",\"longitude_center\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "Because our model won't like NANs we have to replace them by something. We decided to replace them with the median of the corresponding feature. But  we also think having a missing value can actually be a very good predictor. Thats why we will add a \"missing\" column when we have a missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"rank_missing\"]=0\n",
    "df_train[\"atmosphere_missing\"]=0\n",
    "df_train[\"value_missing\"]=0\n",
    "df_train[\"general_missing\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"atmosphere rating\"]=df_train[\"atmosphere rating\"].replace(-1,np.nan)\n",
    "df_train[\"value rating\"]=df_train[\"value rating\"].replace(-1,np.nan)\n",
    "df_train[\"general rating\"]=df_train[\"general rating\"].replace(-1,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train[\"rank\"].isna(),\"rank_missing\"] = 1\n",
    "df_train.loc[df_train[\"atmosphere rating\"].isna(),\"atmosphere_missing\"] = 1\n",
    "df_train.loc[df_train[\"value rating\"].isna(),\"value_missing\"] = 1\n",
    "df_train.loc[df_train[\"general rating\"].isna(),\"general_missing\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imputing our missing values with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputed_data=imp_mean.fit_transform(df_train[[\"rank\",\"general rating\",\"value rating\",\"atmosphere rating\"]])\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"rank\"]=imputed_data[:,0]\n",
    "df_train[\"general rating\"]=imputed_data[:,1]\n",
    "df_train[\"value rating\"]=imputed_data[:,2]\n",
    "df_train[\"atmosphere rating\"]=imputed_data[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaling and then standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"lg_rank\"]=np.log(df_train[\"rank\"])\n",
    "df_train[\"lg_reviews\"]=np.log(df_train[\"number of reviews\"]+1)\n",
    "df_train.drop(columns=[\"rank\",\"number of reviews\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select_dtypes(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select_dtypes(bool).isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no missing values! turn these into zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"travelers choice\"]=df_train[\"travelers choice\"].astype(int)\n",
    "df_train[\"michelin\"]=df_train[\"michelin\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding categorical variables\n",
    "\n",
    "we already explained how we did this and used it in our sprint 1 notebook so excuse us for just copy pasting the code ðŸ˜…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutlihot_col = ['cuisines','special diets',\"meals\",\"restaurant features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in mutlihot_col:\n",
    "    df_train[col]=df_train[col].fillna(col+\"_missing\").str.replace(\" \",\"\").str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[mutlihot_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multi hot encoding of the meals, restaurant features ,cuisines and diets\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlbs=[]\n",
    "columns=[\"meals\",\"restaurant features\",\"cuisines\",\"special diets\"]\n",
    "mh_encodings=[]\n",
    "for col in columns:\n",
    "    mlb= MultiLabelBinarizer()\n",
    "    mlbs.append(mlb)\n",
    "    # X=df_train[col].str.replace(\" \",\"\").str.split(\",\").fillna(\"X\").to_list()\n",
    "    #I want a list of sets that i can then pass to the MultiLabelBinarizer\n",
    "    # lijst=[set(i) for i in X]\n",
    "    mh_encodings.append(mlb.fit_transform(df_train[col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mh_encodings:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mlbs:\n",
    "    print(i.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot encode the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(sparse=False,handle_unknown=\"infrequent_if_exist\")\n",
    "enc.fit(np.array(df_train[\"city\"]).reshape(-1,1))\n",
    "oh_cities=enc.transform(np.array(df_train[\"city\"]).reshape(-1,1))\n",
    "oh_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=[\"cuisines\",\"special diets\",\"meals\",\"restaurant features\",\"city\"],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data=scaler.fit_transform(df_train[[\"general rating\",\"value rating\",\"atmosphere rating\",\"latitude\",\"longitude\",\"lg_rank\",\"lg_reviews\"]])\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"general rating\"]=scaled_data[:,0]\n",
    "df_train[\"value rating\"]=scaled_data[:,1]\n",
    "df_train[\"atmosphere rating\"]=scaled_data[:,2]\n",
    "df_train[\"latitude\"]=scaled_data[:,3]\n",
    "df_train[\"longitude\"]=scaled_data[:,4]\n",
    "df_train[\"lg_rank\"]=scaled_data[:,5]\n",
    "df_train[\"lg_reviews\"]=scaled_data[:,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our label is the pice tag, we will ordinal encode this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.price_tag==\"$\",\"price_tag\"]=0\n",
    "df_train.loc[df_train.price_tag==\"$$ - $$$\",\"price_tag\"]=1\n",
    "df_train.loc[df_train.price_tag==\"$$$$\",\"price_tag\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=df_train[\"price_tag\"].astype(int)\n",
    "df_train.drop(columns=[\"price_tag\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_cities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_encodings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##testing if the shape is correct\n",
    "np.concatenate((oh_cities,mh_encodings[0]),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.concatenate((oh_cities,mh_encodings[0],mh_encodings[1],mh_encodings[2],mh_encodings[3],df_train),axis=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will also make a variable, feature labels that will tell us where each feature in our array comes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels.extend(enc.categories_[0])\n",
    "for i in mlbs:\n",
    "    feature_labels.extend(i.classes_)\n",
    "feature_labels.extend(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_labels), feature_labels[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now apply the same preprocessing for our test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, fill in the missing locations with the city_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df_test.merge(city_centers,on=\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test.latitude.isna(),\"latitude\"]=df_test[df_test.latitude.isna()].latitude_center\n",
    "df_test.loc[df_test.longitude.isna(),\"longitude\"]=df_test[df_test.longitude.isna()].longitude_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.latitude.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.drop(columns=[\"Unnamed: 0\",\"latitude_center\",\"longitude_center\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inserting the missing columns\n",
    "df_test[\"rank_missing\"]=0\n",
    "df_test[\"atmosphere_missing\"]=0\n",
    "df_test[\"value_missing\"]=0\n",
    "df_test[\"general_missing\"]=0\n",
    "df_test[\"atmosphere rating\"]=df_test[\"atmosphere rating\"].replace(-1,np.nan)\n",
    "df_test[\"value rating\"]=df_test[\"value rating\"].replace(-1,np.nan)\n",
    "df_test[\"general rating\"]=df_test[\"general rating\"].replace(-1,np.nan)\n",
    "df_test.loc[df_test[\"rank\"].isna(),\"rank_missing\"] = 1\n",
    "df_test.loc[df_test[\"atmosphere rating\"].isna(),\"atmosphere_missing\"] = 1\n",
    "df_test.loc[df_test[\"value rating\"].isna(),\"value_missing\"] = 1\n",
    "df_test.loc[df_test[\"general rating\"].isna(),\"general_missing\"] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imputing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputing our data\n",
    "imputed_data=imp_mean.transform(df_test[[\"rank\",\"general rating\",\"value rating\",\"atmosphere rating\"]])\n",
    "print(imputed_data.shape)\n",
    "df_test[\"rank\"]=imputed_data[:,0]\n",
    "df_test[\"general rating\"]=imputed_data[:,1]\n",
    "df_test[\"value rating\"]=imputed_data[:,2]\n",
    "df_test[\"atmosphere rating\"]=imputed_data[:,3]\n",
    "df_test[\"lg_rank\"]=np.log(df_test[\"rank\"])\n",
    "df_test[\"lg_reviews\"]=np.log(df_test[\"number of reviews\"]+1)\n",
    "df_test.drop(columns=[\"rank\",\"number of reviews\"],inplace=True)\n",
    "df_test[\"travelers choice\"]=df_test[\"travelers choice\"].astype(int)\n",
    "df_test[\"michelin\"]=df_test[\"michelin\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multihot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in mutlihot_col:\n",
    "    df_test[col]=df_test[col].fillna(col+\"_missing\").str.replace(\" \",\"\").str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multihot encoding\n",
    "# mlbs=[]\n",
    "columns=[\"meals\",\"restaurant features\",\"cuisines\",\"special diets\"]\n",
    "mh_encodings=[]\n",
    "for i,col in enumerate(columns):\n",
    "    mlb= mlbs[i]\n",
    "    mh_encodings.append(mlb.transform(df_test[col]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can already see that there are classs in our test set that don't appear in our trainingsset, we will ignore these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OH encoding\n",
    "# enc=OneHotEncoder(sparse=False,handle_unknown=\"infrequent_if_exist\")\n",
    "enc.transform(np.array(df_test[\"city\"]).reshape(-1,1))\n",
    "oh_cities=enc.transform(np.array(df_test[\"city\"]).reshape(-1,1))\n",
    "df_test.drop(columns=[\"cuisines\",\"special diets\",\"meals\",\"restaurant features\",\"city\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "# scaler = StandardScaler()\n",
    "scaled_data=scaler.transform(df_test[[\"general rating\",\"value rating\",\"atmosphere rating\",\"latitude\",\"longitude\",\"lg_rank\",\"lg_reviews\"]])\n",
    "scaled_data.shape\n",
    "df_test[\"general rating\"]=scaled_data[:,0]\n",
    "df_test[\"value rating\"]=scaled_data[:,1]\n",
    "df_test[\"atmosphere rating\"]=scaled_data[:,2]\n",
    "df_test[\"latitude\"]=scaled_data[:,3]\n",
    "df_test[\"longitude\"]=scaled_data[:,4]\n",
    "df_test[\"lg_rank\"]=scaled_data[:,5]\n",
    "df_test[\"lg_reviews\"]=scaled_data[:,6]\n",
    "df_test.loc[df_test.price_tag==\"$\",\"price_tag\"]=0\n",
    "df_test.loc[df_test.price_tag==\"$$ - $$$\",\"price_tag\"]=1\n",
    "df_test.loc[df_test.price_tag==\"$$$$\",\"price_tag\"]=2\n",
    "\n",
    "y_test=df_test[\"price_tag\"].astype(int)\n",
    "df_test.drop(columns=[\"price_tag\"],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.concatenate((oh_cities,mh_encodings[0],mh_encodings[1],mh_encodings[2],mh_encodings[3],df_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape, X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(100, min_samples_leaf=1)\n",
    "rf.fit(X_train, y_train)\n",
    "balanced_accuracy_score(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is already a good result, we can also find the features that were used the most in the descision trees to make splits (the important features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances=pd.DataFrame(dict(cols=feature_labels, imp=rf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.sort_values(\"imp\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above we can see  the 10 most important features for our random forest ensemble. It is interesting to see that we were right, the fact that a feature is missing is important for the classifier, \"restaurant features missing\" is in the top 10 as a feature. It is also interesting to see that Table service and reviews are the most inmortant features to determine our price tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model selection\n",
    "\n",
    "our first idea was to try out a lot of different classifiers with default parameters, look which ones have the best accuracy and then do a grid search on the best 3 models and pich the best one. When we finished this we realised that our dataset is heavily imbalanced and we have to do something about this.\n",
    "\n",
    "\n",
    "*NOTE: we have class imabalance so we chose models that have the class weight property*\n",
    "\n",
    "we must choose our performance metric carefully because of the class imbalance [this article](\"https://towardsdatascience.com/multiclass-classification-evaluation-with-roc-curves-and-roc-auc-294fd4617e3a\") for inspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "def plot_cm(classifier):\n",
    "    cm=confusion_matrix(y_test, classifier.predict(X_test))\n",
    "    df_cm = pd.DataFrame(cm, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "\n",
    "    sns.heatmap(df_cm, cbar=False, annot=True, square=True, fmt='.0f',\n",
    "                annot_kws={'size': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=[\"svc linear\",\"svc rbf\",\"Logistic Regression\",\"Naive Bayes\",\"Light Gradient Boosting machine(LGBM)\",\"xgboost\",\"catboost\"]\n",
    "scores_list=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svc linear**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quick experiment to see the effect of the class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=SVC(kernel=\"linear\", C=0.025)\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=SVC(kernel=\"linear\", C=0.025,class_weight=\"balanced\")\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)\n",
    "scores_list.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**svc rbf**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma=2, C=1,class_weight=\"balanced\")\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)\n",
    "scores_list.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can already see that by carefully looking at the confusion matrix and not blindly at our classification score we can already see that eventhough this classifier has a better score that the linear SVC, it predicts 1 for almost every input so the model is actually really bad\n",
    "\n",
    "we can also confirm that the balanced accuracy is a better performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**logistic geression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(random_state=0,max_iter=500,class_weight=\"balanced\")\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)\n",
    "scores_list.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naieve Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=GaussianNB() ##here we don't need class weights because the probabilities are calculated from our classes\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)\n",
    "scores_list.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf=KNeighborsClassifier()\n",
    "# clf.fit(X_train,y_train)\n",
    "# mscore=clf.score(X_test,y_test)\n",
    "# print(\"The score is: \",mscore)\n",
    "# scores_list.append(mscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf=RandomForestClassifier(300)\n",
    "# clf.fit(X_train,y_train)\n",
    "# mscore=clf.score(X_test,y_test)\n",
    "# print(\"The score is: \",mscore)\n",
    "# scores_list.append(mscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Light gradient boosting machine (LGBM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LGBMClassifier(random_state=0,class_weight=\"balanced\")\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)\n",
    "scores_list.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBOOST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with help from [Unbalanced multiclass data with XGBoost](\"https://datascience.stackexchange.com/questions/16342/unbalanced-multiclass-data-with-xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=XGBClassifier(use_label_encoder=False,random_state=0)\n",
    "clf.fit(X_train,y_train,sample_weight=classes_weights)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)\n",
    "scores_list.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**catboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "weights = class_weight.compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869:\tlearn: 0.1253935\ttotal: 12.1s\tremaining: 1.8s\n",
      "870:\tlearn: 0.1252707\ttotal: 12.1s\tremaining: 1.79s\n",
      "871:\tlearn: 0.1252555\ttotal: 12.1s\tremaining: 1.77s\n",
      "872:\tlearn: 0.1251303\ttotal: 12.1s\tremaining: 1.76s\n",
      "873:\tlearn: 0.1249897\ttotal: 12.1s\tremaining: 1.75s\n",
      "874:\tlearn: 0.1248531\ttotal: 12.1s\tremaining: 1.73s\n",
      "875:\tlearn: 0.1247896\ttotal: 12.1s\tremaining: 1.72s\n",
      "876:\tlearn: 0.1247350\ttotal: 12.2s\tremaining: 1.7s\n",
      "877:\tlearn: 0.1245401\ttotal: 12.2s\tremaining: 1.69s\n",
      "878:\tlearn: 0.1245072\ttotal: 12.2s\tremaining: 1.68s\n",
      "879:\tlearn: 0.1242438\ttotal: 12.2s\tremaining: 1.66s\n",
      "880:\tlearn: 0.1240938\ttotal: 12.2s\tremaining: 1.65s\n",
      "881:\tlearn: 0.1239845\ttotal: 12.2s\tremaining: 1.64s\n",
      "882:\tlearn: 0.1237789\ttotal: 12.3s\tremaining: 1.63s\n",
      "883:\tlearn: 0.1234888\ttotal: 12.3s\tremaining: 1.61s\n",
      "884:\tlearn: 0.1234390\ttotal: 12.3s\tremaining: 1.6s\n",
      "885:\tlearn: 0.1233749\ttotal: 12.3s\tremaining: 1.58s\n",
      "886:\tlearn: 0.1232645\ttotal: 12.3s\tremaining: 1.57s\n",
      "887:\tlearn: 0.1231295\ttotal: 12.3s\tremaining: 1.56s\n",
      "888:\tlearn: 0.1230778\ttotal: 12.4s\tremaining: 1.54s\n",
      "889:\tlearn: 0.1228702\ttotal: 12.4s\tremaining: 1.53s\n",
      "890:\tlearn: 0.1228527\ttotal: 12.4s\tremaining: 1.51s\n",
      "891:\tlearn: 0.1227387\ttotal: 12.4s\tremaining: 1.5s\n",
      "892:\tlearn: 0.1223537\ttotal: 12.4s\tremaining: 1.49s\n",
      "893:\tlearn: 0.1222667\ttotal: 12.4s\tremaining: 1.47s\n",
      "894:\tlearn: 0.1221419\ttotal: 12.4s\tremaining: 1.46s\n",
      "895:\tlearn: 0.1220962\ttotal: 12.4s\tremaining: 1.45s\n",
      "896:\tlearn: 0.1220762\ttotal: 12.5s\tremaining: 1.43s\n",
      "897:\tlearn: 0.1220030\ttotal: 12.5s\tremaining: 1.42s\n",
      "898:\tlearn: 0.1217624\ttotal: 12.5s\tremaining: 1.4s\n",
      "899:\tlearn: 0.1215506\ttotal: 12.5s\tremaining: 1.39s\n",
      "900:\tlearn: 0.1215372\ttotal: 12.5s\tremaining: 1.38s\n",
      "901:\tlearn: 0.1215256\ttotal: 12.5s\tremaining: 1.36s\n",
      "902:\tlearn: 0.1215010\ttotal: 12.5s\tremaining: 1.35s\n",
      "903:\tlearn: 0.1213029\ttotal: 12.6s\tremaining: 1.33s\n",
      "904:\tlearn: 0.1212282\ttotal: 12.6s\tremaining: 1.32s\n",
      "905:\tlearn: 0.1210300\ttotal: 12.6s\tremaining: 1.31s\n",
      "906:\tlearn: 0.1209182\ttotal: 12.6s\tremaining: 1.29s\n",
      "907:\tlearn: 0.1207840\ttotal: 12.6s\tremaining: 1.28s\n",
      "908:\tlearn: 0.1207453\ttotal: 12.6s\tremaining: 1.26s\n",
      "909:\tlearn: 0.1206481\ttotal: 12.6s\tremaining: 1.25s\n",
      "910:\tlearn: 0.1205633\ttotal: 12.6s\tremaining: 1.24s\n",
      "911:\tlearn: 0.1203261\ttotal: 12.7s\tremaining: 1.22s\n",
      "912:\tlearn: 0.1201414\ttotal: 12.7s\tremaining: 1.21s\n",
      "913:\tlearn: 0.1200069\ttotal: 12.7s\tremaining: 1.19s\n",
      "914:\tlearn: 0.1199657\ttotal: 12.7s\tremaining: 1.18s\n",
      "915:\tlearn: 0.1199094\ttotal: 12.7s\tremaining: 1.17s\n",
      "916:\tlearn: 0.1197161\ttotal: 12.7s\tremaining: 1.15s\n",
      "917:\tlearn: 0.1196076\ttotal: 12.7s\tremaining: 1.14s\n",
      "918:\tlearn: 0.1194723\ttotal: 12.7s\tremaining: 1.12s\n",
      "919:\tlearn: 0.1192025\ttotal: 12.8s\tremaining: 1.11s\n",
      "920:\tlearn: 0.1191252\ttotal: 12.8s\tremaining: 1.09s\n",
      "921:\tlearn: 0.1190006\ttotal: 12.8s\tremaining: 1.08s\n",
      "922:\tlearn: 0.1189068\ttotal: 12.8s\tremaining: 1.07s\n",
      "923:\tlearn: 0.1187894\ttotal: 12.8s\tremaining: 1.05s\n",
      "924:\tlearn: 0.1186509\ttotal: 12.8s\tremaining: 1.04s\n",
      "925:\tlearn: 0.1185022\ttotal: 12.8s\tremaining: 1.02s\n",
      "926:\tlearn: 0.1184230\ttotal: 12.8s\tremaining: 1.01s\n",
      "927:\tlearn: 0.1183159\ttotal: 12.8s\tremaining: 996ms\n",
      "928:\tlearn: 0.1181419\ttotal: 12.8s\tremaining: 982ms\n",
      "929:\tlearn: 0.1179760\ttotal: 12.9s\tremaining: 968ms\n",
      "930:\tlearn: 0.1179081\ttotal: 12.9s\tremaining: 954ms\n",
      "931:\tlearn: 0.1176854\ttotal: 12.9s\tremaining: 941ms\n",
      "932:\tlearn: 0.1176378\ttotal: 12.9s\tremaining: 929ms\n",
      "933:\tlearn: 0.1176026\ttotal: 13s\tremaining: 916ms\n",
      "934:\tlearn: 0.1173580\ttotal: 13s\tremaining: 902ms\n",
      "935:\tlearn: 0.1173033\ttotal: 13s\tremaining: 889ms\n",
      "936:\tlearn: 0.1172271\ttotal: 13s\tremaining: 875ms\n",
      "937:\tlearn: 0.1171295\ttotal: 13s\tremaining: 861ms\n",
      "938:\tlearn: 0.1168825\ttotal: 13s\tremaining: 847ms\n",
      "939:\tlearn: 0.1167039\ttotal: 13.1s\tremaining: 833ms\n",
      "940:\tlearn: 0.1166469\ttotal: 13.1s\tremaining: 819ms\n",
      "941:\tlearn: 0.1164676\ttotal: 13.1s\tremaining: 807ms\n",
      "942:\tlearn: 0.1164065\ttotal: 13.1s\tremaining: 793ms\n",
      "943:\tlearn: 0.1163211\ttotal: 13.1s\tremaining: 779ms\n",
      "944:\tlearn: 0.1161986\ttotal: 13.1s\tremaining: 765ms\n",
      "945:\tlearn: 0.1161397\ttotal: 13.2s\tremaining: 751ms\n",
      "946:\tlearn: 0.1160772\ttotal: 13.2s\tremaining: 737ms\n",
      "947:\tlearn: 0.1158990\ttotal: 13.2s\tremaining: 723ms\n",
      "948:\tlearn: 0.1158239\ttotal: 13.2s\tremaining: 709ms\n",
      "949:\tlearn: 0.1156846\ttotal: 13.2s\tremaining: 695ms\n",
      "950:\tlearn: 0.1155183\ttotal: 13.2s\tremaining: 681ms\n",
      "951:\tlearn: 0.1153824\ttotal: 13.2s\tremaining: 667ms\n",
      "952:\tlearn: 0.1152298\ttotal: 13.2s\tremaining: 653ms\n",
      "953:\tlearn: 0.1150625\ttotal: 13.3s\tremaining: 639ms\n",
      "954:\tlearn: 0.1150306\ttotal: 13.3s\tremaining: 626ms\n",
      "955:\tlearn: 0.1149104\ttotal: 13.3s\tremaining: 612ms\n",
      "956:\tlearn: 0.1148496\ttotal: 13.3s\tremaining: 598ms\n",
      "957:\tlearn: 0.1147487\ttotal: 13.3s\tremaining: 585ms\n",
      "958:\tlearn: 0.1147366\ttotal: 13.4s\tremaining: 571ms\n",
      "959:\tlearn: 0.1146527\ttotal: 13.4s\tremaining: 557ms\n",
      "960:\tlearn: 0.1146084\ttotal: 13.4s\tremaining: 543ms\n",
      "961:\tlearn: 0.1145251\ttotal: 13.4s\tremaining: 529ms\n",
      "962:\tlearn: 0.1143156\ttotal: 13.4s\tremaining: 515ms\n",
      "963:\tlearn: 0.1141759\ttotal: 13.4s\tremaining: 502ms\n",
      "964:\tlearn: 0.1140061\ttotal: 13.4s\tremaining: 487ms\n",
      "965:\tlearn: 0.1138815\ttotal: 13.5s\tremaining: 474ms\n",
      "966:\tlearn: 0.1138168\ttotal: 13.5s\tremaining: 460ms\n",
      "967:\tlearn: 0.1137400\ttotal: 13.5s\tremaining: 446ms\n",
      "968:\tlearn: 0.1137114\ttotal: 13.5s\tremaining: 432ms\n",
      "969:\tlearn: 0.1136727\ttotal: 13.5s\tremaining: 418ms\n",
      "970:\tlearn: 0.1136567\ttotal: 13.5s\tremaining: 404ms\n",
      "971:\tlearn: 0.1135911\ttotal: 13.5s\tremaining: 390ms\n",
      "972:\tlearn: 0.1135740\ttotal: 13.5s\tremaining: 376ms\n",
      "973:\tlearn: 0.1134384\ttotal: 13.5s\tremaining: 362ms\n",
      "974:\tlearn: 0.1133622\ttotal: 13.6s\tremaining: 348ms\n",
      "975:\tlearn: 0.1132485\ttotal: 13.6s\tremaining: 334ms\n",
      "976:\tlearn: 0.1131740\ttotal: 13.6s\tremaining: 320ms\n",
      "977:\tlearn: 0.1130943\ttotal: 13.6s\tremaining: 306ms\n",
      "978:\tlearn: 0.1130016\ttotal: 13.6s\tremaining: 292ms\n",
      "979:\tlearn: 0.1129009\ttotal: 13.6s\tremaining: 278ms\n",
      "980:\tlearn: 0.1127456\ttotal: 13.6s\tremaining: 264ms\n",
      "981:\tlearn: 0.1126845\ttotal: 13.6s\tremaining: 250ms\n",
      "982:\tlearn: 0.1125149\ttotal: 13.7s\tremaining: 236ms\n",
      "983:\tlearn: 0.1124586\ttotal: 13.7s\tremaining: 222ms\n",
      "984:\tlearn: 0.1124393\ttotal: 13.7s\tremaining: 208ms\n",
      "985:\tlearn: 0.1122428\ttotal: 13.7s\tremaining: 194ms\n",
      "986:\tlearn: 0.1120887\ttotal: 13.7s\tremaining: 180ms\n",
      "987:\tlearn: 0.1120662\ttotal: 13.7s\tremaining: 166ms\n",
      "988:\tlearn: 0.1118314\ttotal: 13.7s\tremaining: 153ms\n",
      "989:\tlearn: 0.1116565\ttotal: 13.7s\tremaining: 139ms\n",
      "990:\tlearn: 0.1116049\ttotal: 13.7s\tremaining: 125ms\n",
      "991:\tlearn: 0.1114912\ttotal: 13.8s\tremaining: 111ms\n",
      "992:\tlearn: 0.1114078\ttotal: 13.8s\tremaining: 97.1ms\n",
      "993:\tlearn: 0.1113536\ttotal: 13.8s\tremaining: 83.2ms\n",
      "994:\tlearn: 0.1113432\ttotal: 13.8s\tremaining: 69.3ms\n",
      "995:\tlearn: 0.1113162\ttotal: 13.8s\tremaining: 55.4ms\n",
      "996:\tlearn: 0.1112114\ttotal: 13.8s\tremaining: 41.6ms\n",
      "997:\tlearn: 0.1110543\ttotal: 13.8s\tremaining: 27.7ms\n",
      "998:\tlearn: 0.1110081\ttotal: 13.8s\tremaining: 13.8ms\n",
      "999:\tlearn: 0.1109564\ttotal: 13.8s\tremaining: 0us\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [99], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m clf\u001b[39m=\u001b[39mCatBoostClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,class_weights\u001b[39m=\u001b[39mclass_weights)\n\u001b[1;32m----> 2\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m      3\u001b[0m pred\u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m mscore\u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39mscore(X_test,y_test)\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\catboost\\core.py:5007\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5005\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5007\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[0;32m   5008\u001b[0m           eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5009\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5010\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\catboost\\core.py:2278\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2274\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2276\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2277\u001b[0m     plot_wrapper(plot, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2278\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2279\u001b[0m         train_pool,\n\u001b[0;32m   2280\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2281\u001b[0m         params,\n\u001b[0;32m   2282\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2283\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2284\u001b[0m     )\n\u001b[0;32m   2286\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2287\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32md:\\programmas_unif\\miniconda\\lib\\site-packages\\catboost\\core.py:1705\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1705\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1706\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf=CatBoostClassifier(random_state=0,class_weights=class_weights)\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)\n",
    "scores_list.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb=pd.DataFrame(list(zip(classifiers,scores_list)),columns=['Classifier','Score'])\n",
    "sb.sort_values(\"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch\n",
    "Now we will try to squeeze the last drops of performance out of our best model, the svc with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_grid={\n",
    "    \"kernel\":[\"linear\"],\n",
    "    \"C\":[0.01,0.1,1,10,100],\n",
    "\n",
    "}\n",
    "# LGBM_grid = {'n_estimators': [50, 100, 150, 200],\n",
    "#         'max_depth': [4, 8, 12],\n",
    "#         'learning_rate': [0.05, 0.1, 0.15]}\n",
    "xgboost_grid = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "catboost_grid={'learning_rate': [0.01, 0.1,1],\n",
    "        'n_estimators':[100,200,400],\n",
    "        'depth': [4, 10,15,20,30],\n",
    "        'l2_leaf_reg': [0,1, 3, 5, 9]}\n",
    "\n",
    "# rf_grid={\n",
    "#     \"n_estimators\":[100,200,300,400],\n",
    "#     \"max_depth\":[1,2,3,4,5,6,7,8],\n",
    "#     'min_samples_leaf':[2,4]\n",
    "# }\n",
    "\n",
    "log_grid={\n",
    "    \"penalty\":[\"l1\", \"l2\", \"elasticnet\" , \"none\" ],\n",
    "    \"C\":[0.01,0.1,1,10],\n",
    "    \"max_iter\":[100,150,200,300]\n",
    "}\n",
    "final_class=['linear_svc','xgboost_classifier','catboost_classifier','logistic_regression']\n",
    "final_scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_clf=GridSearchCV(estimator=SVC(class_weight=\"balanced\"),param_grid=linear_svc_grid,n_jobs=1,cv=5,verbose=True)\n",
    "linear_svc_clf.fit(X_train,y_train)\n",
    "dump(linear_svc_clf, 'linear_svc_clf.joblib')\n",
    "\n",
    "pred=linear_svc_clf.predict(X_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "final_scores.append(balanced_score)\n",
    "plot_cm(linear_svc_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_clf=GridSearchCV(estimator=XGBClassifier(use_label_encoder=False),param_grid=xgboost_grid,n_jobs=1,cv=5,verbose=True)\n",
    "\n",
    "#Fit the model\n",
    "xgboost_clf.fit(X_train,y_train,sample_weight=classes_weights)\n",
    "#Score and Store the model\n",
    "dump(xgboost_clf, 'xgboost_clf.joblib') \n",
    "\n",
    "pred=xgboost_clf.predict(X_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "final_scores.append(balanced_score)\n",
    "plot_cm(xgboost_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_clf=GridSearchCV(estimator=CatBoostClassifier(class_weights=class_weights),param_grid=catboost_grid,n_jobs=1,cv=5,verbose=True)\n",
    "\n",
    "#Fit the model\n",
    "catboost_clf.fit(X_train,y_train)\n",
    "dump(catboost_clf, 'catboost_clf.joblib') \n",
    "\n",
    "pred=catboost_clf.predict(X_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "final_scores.append(balanced_score)\n",
    "plot_cm(catboost_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf=GridSearchCV(estimator=LogisticRegression(class_weight=\"balanced\"),param_grid=log_grid,n_jobs=1,cv=5,verbose=True)\n",
    "\n",
    "#Fit the model\n",
    "log_reg_clf.fit(X_train,y_train)\n",
    "\n",
    "dump(log_reg_clf, 'logistic_regression.joblib') \n",
    "#Score and Store the model\n",
    "pred=log_reg_clf.predict(X_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "final_scores.append(balanced_score)\n",
    "plot_cm(log_reg_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sb=pd.DataFrame(list(zip(final_class,final_scores)),columns=['Classifier','Score'])\n",
    "final_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "als moeilijk gaat om expensive restaurants eruit te halen probeer die eruit te krijgen met isolation forest of pca en de rest met binary classifiation\n",
    "\n",
    "voor de laatste kan je dan grid search doen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying out TTA (test time augmentation)\n",
    "\n",
    "Test-time augmentation, or TTA for short, is a technique for improving the skill of predictive models.\n",
    "\n",
    "It is typically used to improve the predictive performance of deep learning models on image datasets where predictions are averaged across multiple augmented versions of each image in the test dataset.\n",
    "\n",
    "Although popular with image datasets and neural network models, test-time augmentation can be used with any machine learning algorithm on tabular datasets, such as those often seen in regression and classification predictive modeling problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test set for a row of real data with an unknown label\n",
    "from numpy.random import normal\n",
    "from scipy.stats import mode\n",
    "\n",
    "def create_test_set(row, n_cases=3, feature_scale=0.2):\n",
    "\ttest_set = list()\n",
    "\ttest_set.append(row)\n",
    "\t# make copies of row\n",
    "\tfor _ in range(n_cases):\n",
    "\t\t# create vector of random gaussians\n",
    "\t\tgauss = normal(loc=0.0, scale=feature_scale, size=len(row))\n",
    "\t\t# add to test case\n",
    "\t\tnew_row = row + gauss\n",
    "\t\t# store in test set\n",
    "\t\ttest_set.append(new_row)\n",
    "\treturn test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using test-time augmentation\n",
    "def test_time_augmentation(model, X_test, noise):\n",
    "\t# evaluate model\n",
    "\ty_hat = list()\n",
    "\tfor i in range(X_test.shape[0]):\n",
    "\t\t# retrieve the row\n",
    "\t\trow = X_test[i]\n",
    "\t\t# create the test set\n",
    "\t\ttest_set = create_test_set(row, feature_scale=noise)\n",
    "\t\t# make a prediction for all examples in the test set\n",
    "\t\tlabels = model.predict(test_set)\n",
    "\t\t# select the label as the mode of the distribution\n",
    "\t\tlabel, _ = mode(labels)\n",
    "\t\t# store the prediction\n",
    "\t\ty_hat.append(label)\n",
    "\treturn y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=SVC(kernel=\"linear\", C=0.025,class_weight=\"balanced\")\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)\n",
    "mscore=clf.score(X_test,y_test)\n",
    "balanced_score=balanced_accuracy_score(y_test,pred)\n",
    "print(\"The score is: \",mscore)\n",
    "print(\"The balanced accuracy is: \",balanced_score)\n",
    "scores_list.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate different number of synthetic examples created at test time\n",
    "examples = np.arange(0.01,1,0.01)\n",
    "results = list()\n",
    "for e in examples:\n",
    "\tpred = test_time_augmentation(clf, X_test, e)\n",
    "\tbalanced_score=balanced_accuracy_score(y_test,pred)\n",
    "\tprint(\"The balanced accuracy is: \",balanced_score)\n",
    "\tresults.append(balanced_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"feature_scaleing\":examples,\"results\":results})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.results.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.results>=0.68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that, eventhough it's a tiny improvement, we actually were able to improve our model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b781f973879b6653a182b86dce637bbad8607b90046e75a81b5febd27741eaed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
